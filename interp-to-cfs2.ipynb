{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "fyear = 'raw-data/c2/2019'\n",
    "\n",
    "# import packages\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sd = pd.read_csv('data/c2/sd-for-c2-2019.csv')\n",
    "\n",
    "t = sd['datetime']\n",
    "lon = sd['lon']\n",
    "lat = sd['lat']\n",
    "QL = sd['QL']\n",
    "QS = sd['QS']\n",
    "qs = sd['qs']\n",
    "qa = sd['qa']\n",
    "SST = sd['SST']\n",
    "T = sd['T']\n",
    "V = sd['V']\n",
    "\n",
    "land = pd.read_csv('check-land/c2land.csv')\n",
    "land_lat = land['lat']\n",
    "land_lon = land['lng']\n",
    "land = [land_lon,land_lat]\n",
    "land = np.array(land)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## export a SD file with ... ##\n",
    "# time, lon, lat, QL, QS, qs, qa, SST, T, V\n",
    "sd0 = pd.read_csv('data/sd/avg-at30-2017.csv') # or something... ## change this ##\n",
    "\n",
    "p = sd0['p'] # hPa\n",
    "T = sd0['T']+273.15 # C to K\n",
    "SST = sd0['SST']+273.15 # C to K\n",
    "RH = sd0['RH'] # %\n",
    "\n",
    "# conversions for sea\n",
    "# sea saturation vapor pressure : Wallace and Hobbs, Second Edition (pg. 99)\n",
    "es = 6.11*np.exp((2.50*10**6*18.016/(1000*8.3145))*((1/273)-(1/SST))) #hPa\n",
    "e = es * (RH/100.0) # hPa\n",
    "qs = 0.622*(e/(p-e))*1000 #g/kg\n",
    "\n",
    "# conversions for air\n",
    "es = 6.11*np.exp((2.50*10**6*18.016/(1000*8.3145))*((1/273)-(1/T))) # air saturation vapor pressure : Wallace and Hobbs, Second Edition (pg. 99)\n",
    "e = es * (RH/100.0) # vapor pressure : Wallace and Hobbs, Second Edition (pg. 82)\n",
    "qa = 0.622*(e/(p-e))*1000 # specific humidity of atmosphere : Wallace and Hobbs (pg. 80)\n",
    "\n",
    "t = sd0['datetime']\n",
    "lon = sd0['longitude']\n",
    "lat = sd0['latitude']\n",
    "QL = sd0['QL']\n",
    "QS = sd0['QS']\n",
    "V = sd0['V']\n",
    "\n",
    "sd = np.array([t,lon,lat, QL,qs,qa,QS,SST,T,V,p])\n",
    "sd = pd.DataFrame(sd.T,columns=['datetime','lon','lat','QL','qa','qs','QS','SST','T','V','p'])\n",
    "sd.to_csv('data/sd/sd-for-c2-2017.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great-circle distance between two points on the Earth's surface\n",
    "    using the Haversine formula.\n",
    "    \n",
    "    lon1, lat1: Longitude and latitude of the first point (in degrees).\n",
    "    lon2, lat2: Longitude and latitude of the second point (in degrees).\n",
    "    \n",
    "    Returns the distance in kilometers.\n",
    "    \"\"\"\n",
    "    # Convert degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(math.radians, [lon1, lat1, lon2, lat2])\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = 6371 * c  # Earth's radius in kilometers\n",
    "    return distance\n",
    "def find_nearest(coordinates, target_point):\n",
    "    closest_index = 0\n",
    "    closest_distance = haversine(target_point[0], target_point[1], coordinates[0][0], coordinates[0][1])\n",
    "    for i, coordinate in enumerate(coordinates):\n",
    "        distance = haversine(target_point[0], target_point[1], coordinate[0], coordinate[1])\n",
    "        if distance < closest_distance:\n",
    "            closest_index = i\n",
    "            closest_distance = distance\n",
    "    return closest_index\n",
    "# pretty ones from Eli\n",
    "def solution(X1: np.ndarray, X2: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        X1: (1D array_like)\n",
    "        X2: (1D array_like)\n",
    "    Returns:\n",
    "        X1_indices where value exists in X2 as well\n",
    "        X2_indices where value exists in X1 as well\n",
    "    Note: the returned indices array are ordered smallest to greatest. by the value they correspond to\n",
    "    that is to say X1[X1_indices] is a sorted list, u could do X1[X1_indices.sort()] to get the values in \n",
    "    the order they appear in the orignal X1\n",
    "    \"\"\"\n",
    "    inter = np.intersect1d(X1, X2)\n",
    "    def helper(inter: np.ndarray, x: np.ndarray):\n",
    "        sorter = np.argsort(x)\n",
    "        searchsorted_left = np.searchsorted(x, inter, sorter=sorter,side='left')\n",
    "        searchsorted_right = np.searchsorted(x, inter, sorter=sorter,side='right')\n",
    "        values = vrange(searchsorted_left, searchsorted_right) \n",
    "        return sorter[values] # optional to sort this if u care?\n",
    "    return helper(inter, X1), helper(inter, X2)\n",
    "def vrange(starts: np.ndarray, stops: np.ndarray):\n",
    "    \"\"\"Create concatenated ranges of integers for multiple start/stop\n",
    "    Parameters:\n",
    "        starts (1-D array_like): starts for each range\n",
    "        stops (1-D array_like): stops for each range (same shape as starts)\n",
    "    Returns:\n",
    "        numpy.ndarray: concatenated ranges\n",
    "    For example:\n",
    "        >>> starts = [1, 3, 4, 6]\n",
    "        >>> stops  = [1, 5, 7, 6]\n",
    "        >>> vrange(starts, stops)\n",
    "        array([3, 4, 4, 5, 6])\n",
    "    \"\"\"\n",
    "    stops = np.asarray(stops)\n",
    "    l = stops - starts # Lengths of each range.\n",
    "    return np.repeat(stops - l.cumsum(), l) + np.arange(l.sum())\n",
    "def find_near(array, value): # finds closest value\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "prd = fyear+'-QL.nc'\n",
    "f = nc.Dataset(prd,mode='r')\n",
    "tprd = f.variables['time'][:]\n",
    "for index,timeprd in enumerate(tprd):\n",
    "    tprd[index]=int(timeprd)+ 1800\n",
    "lonprd = f.variables['longitude'][:] # degrees\n",
    "for index,lng in enumerate(lonprd):\n",
    "    if lng > 180:\n",
    "        lonprd[index] = lng - 360\n",
    "latprd = f.variables['latitude'][:] # degrees\n",
    "QLprd = f.variables['lhtfl'][:] # W*m^-2\n",
    "prd = fyear+'-q.nc'\n",
    "f = nc.Dataset(prd,mode='r')\n",
    "qaprd = f.variables['q2m'][:]\n",
    "prd = fyear+'-QS.nc'\n",
    "f = nc.Dataset(prd,mode='r')\n",
    "QSprd = f.variables['shtfl'][:] # W*m^-2\n",
    "prd = fyear+'-SST.nc'\n",
    "f = nc.Dataset(prd,mode='r')\n",
    "SSTprd = f.variables['tmpsfc'][:] # K\n",
    "prd = fyear+'-T.nc'\n",
    "f = nc.Dataset(prd,mode='r')\n",
    "Tprd = f.variables['tmp2m'][:] # K\n",
    "prd = fyear+'-u.nc'\n",
    "f = nc.Dataset(prd,mode='r')\n",
    "uprd = f.variables['wnd10mu'][:] # m*s^-1\n",
    "prd = fyear+'-v.nc'\n",
    "f = nc.Dataset(prd,mode='r')\n",
    "vprd = f.variables['wnd10mv'][:] # m*s^-1\n",
    "prd = fyear+'-p.nc'\n",
    "f = nc.Dataset(prd,mode='r')\n",
    "pprd = f.variables['pressfc'][:] # \n",
    "\n",
    "Vprd = np.sqrt(uprd**2+vprd**2)\n",
    "\n",
    "# organize coordinates\n",
    "location = np.stack((lon,lat),axis=1) # set saildrone coordinates\n",
    "\n",
    "gridlocation = [] # set MERRA2 coordinates\n",
    "grididx = []\n",
    "for idx_lon, lon in enumerate(lonprd):\n",
    "    for idx_lat,lat in enumerate(latprd):\n",
    "        gridlocation.append([lon,lat])\n",
    "        grididx.append([idx_lon,idx_lat])\n",
    "gridlocation = np.asarray(gridlocation)\n",
    "grididx = np.asarray(grididx)\n",
    "\n",
    "lonidx = []\n",
    "latidx = []\n",
    "tttidx = []\n",
    "for idx,loc in enumerate(location):\n",
    "    k = find_nearest(gridlocation, loc)\n",
    "    # Initialize a flag to check if any match is found\n",
    "    match_found = False\n",
    "    for land_coord in land.T:\n",
    "        if gridlocation[k][0] == land_coord[0] and gridlocation[k][1] == land_coord[1]:\n",
    "            # Set the flag to True if a match is found\n",
    "            match_found = True\n",
    "            break\n",
    "    # Append indices only if no match is found\n",
    "    if not match_found:\n",
    "        lonidx.append(grididx[k, 0])\n",
    "        latidx.append(grididx[k, 1])\n",
    "        tttidx.append(idx)\n",
    "\n",
    "t = np.copy(t[tttidx])\n",
    "\n",
    "# organize times\n",
    "[idxprd,idxsd] = solution(tprd,t)\n",
    "idxprd = np.array(idxprd)\n",
    "tidxprd = np.copy(tprd[idxprd])\n",
    "QLidxprd = np.copy(QLprd[idxprd])\n",
    "QSidxprd = np.copy(QSprd[idxprd])\n",
    "Tidxprd = np.copy(Tprd[idxprd])\n",
    "SSTidxprd = np.copy(SSTprd[idxprd])\n",
    "qaidxprd = np.copy(qaprd[idxprd])\n",
    "Vidxprd = np.copy(Vprd[idxprd])\n",
    "pidxprd = np.copy(pprd[idxprd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate MERRA2 variables\n",
    "QL0 = []\n",
    "qa0 = []\n",
    "QS0 = []\n",
    "SST0 = []\n",
    "T0 = []\n",
    "SST0 = []\n",
    "V0 = []\n",
    "p0 = []\n",
    "\n",
    "for tt in t:\n",
    "    for idx,ttprd in enumerate(tidxprd):\n",
    "        if tt == ttprd:\n",
    "            QL0.append(QLidxprd[idx])\n",
    "            qa0.append(qaidxprd[idx])\n",
    "            QS0.append(QSidxprd[idx])\n",
    "            SST0.append(SSTidxprd[idx])\n",
    "            T0.append(Tidxprd[idx])\n",
    "            V0.append(Vidxprd[idx])\n",
    "            p0.append(pidxprd[idx])\n",
    "QL0 = np.array(QL0)\n",
    "qa0 = np.array(qa0)\n",
    "QS0 = np.array(QS0)\n",
    "SST0 = np.array(SST0)\n",
    "T0 = np.array(T0)\n",
    "V0 = np.array(V0)\n",
    "p0 = np.array(p0)\n",
    "\n",
    "\n",
    "tidx = np.arange(0,len(t),1)\n",
    "QL = []\n",
    "qa = []\n",
    "QS = []\n",
    "SST = []\n",
    "T = []\n",
    "SST = []\n",
    "V = []\n",
    "p = []\n",
    "\n",
    "for j in tidx:\n",
    "    # first closest\n",
    "    QL.append(QL0[j,latidx[j],lonidx[j]])\n",
    "    qa.append(qa0[j,latidx[j],lonidx[j]])\n",
    "    QS.append(QS0[j,latidx[j],lonidx[j]])\n",
    "    SST.append(SST0[j,latidx[j],lonidx[j]])\n",
    "    T.append(T0[j,latidx[j],lonidx[j]])\n",
    "    V.append(V0[j,latidx[j],lonidx[j]])\n",
    "    p.append(p0[j,latidx[j],lonidx[j]])\n",
    "\n",
    "latprd = np.array(latprd[latidx])\n",
    "lonprd = np.array(lonprd[lonidx])\n",
    "qa = np.array(qa)\n",
    "SST = np.array(SST)\n",
    "T = np.array(T)\n",
    "p = np.array(p)\n",
    "\n",
    "esT = 6.11*2.71828**(5420*(1/273-1/T)) # air saturation vapor pressure OK\n",
    "esSST = 6.11*2.71828**(5420*(1/273-1/SST)) # sea saturation vapor pressure OK\n",
    "\n",
    "rh = p*(1/(0.622*esT*((qa+1)/qa)))\n",
    "e = esSST*rh/100\n",
    "\n",
    "qs = 0.622*(e/(p/100-e))*1000\n",
    "qa = qa*1000 # kg/kg -> g/kg\n",
    "\n",
    "lon = np.copy(sd['lon'][tttidx])\n",
    "lat = np.copy(sd['lat'][tttidx])\n",
    "prd = np.array([t,lon,lat,lonprd,latprd,QL,qs,qa,QS,SST,T,V])\n",
    "prd = prd.T\n",
    "prd = np.ma.masked_where(prd == 9.999E20, prd)\n",
    "prd = np.ma.compress_rows(prd)\n",
    "prd = pd.DataFrame(prd,columns=['datetime','lon','lat','lon-prd','lat-prd','QL','qs','qa','QS','SST','T','V'])\n",
    "prd.to_csv('data/c2/c2-2019.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15468\n"
     ]
    }
   ],
   "source": [
    "m = pd.read_csv('data/c2/c2-2019.csv')\n",
    "print(len(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15468\n",
      "15468\n"
     ]
    }
   ],
   "source": [
    "m = pd.read_csv('data/c2/c2-2018.csv')\n",
    "value_to_remove = 9.999000260554008e+20  # Change this to the value you want to remove\n",
    "m = m[m['T'] != value_to_remove]\n",
    "m = m[m['SST'] != value_to_remove]\n",
    "m.to_csv('data/c2/c2-2018.csv', encoding='utf-8', index=False)\n",
    "\n",
    "m = pd.read_csv('data/c2/c2-2019.csv')\n",
    "print(len(m))\n",
    "value_to_remove = 9.999000260554008e+20  # Change this to the value you want to remove\n",
    "m = m[m['T'] != value_to_remove]\n",
    "m.to_csv('data/c2/c2-2019.csv', encoding='utf-8', index=False)\n",
    "print(len(m))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arctic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
