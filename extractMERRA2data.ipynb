{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERRA2 DATASET INTERPOLATION\n",
    "# Subhatra Sivam, Eli Lichtblau\n",
    "\n",
    "# import packages\n",
    "from math import radians\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "import time\n",
    "\n",
    "# functions\n",
    "# pretty ones from Eli\n",
    "def solution(X1: np.ndarray, X2: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        X1: (1D array_like)\n",
    "        X2: (1D array_like)\n",
    "    Returns:\n",
    "        X1_indices where value exists in X2 as well\n",
    "        X2_indices where value exists in X1 as well\n",
    "    Note: the returned indices array are ordered smallest to greatest. by the value they correspond to\n",
    "    that is to say X1[X1_indices] is a sorted list, u could do X1[X1_indices.sort()] to get the values in \n",
    "    the order they appear in the orignal X1\n",
    "    \n",
    "    \"\"\"\n",
    "    inter = np.intersect1d(X1, X2)\n",
    "    def helper(inter: np.ndarray, x: np.ndarray):\n",
    "        sorter = np.argsort(x)\n",
    "        searchsorted_left = np.searchsorted(x, inter, sorter=sorter,side='left')\n",
    "        searchsorted_right = np.searchsorted(x, inter, sorter=sorter,side='right')\n",
    "        values = vrange(searchsorted_left, searchsorted_right) \n",
    "        return sorter[values] # optional to sort this if u care?\n",
    "        \n",
    "\n",
    "    return helper(inter, X1), helper(inter, X2)\n",
    "def vrange(starts: np.ndarray, stops: np.ndarray):\n",
    "    \"\"\"Create concatenated ranges of integers for multiple start/stop\n",
    "\n",
    "    Parameters:\n",
    "        starts (1-D array_like): starts for each range\n",
    "        stops (1-D array_like): stops for each range (same shape as starts)\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: concatenated ranges\n",
    "\n",
    "    For example:\n",
    "\n",
    "        >>> starts = [1, 3, 4, 6]\n",
    "        >>> stops  = [1, 5, 7, 6]\n",
    "        >>> vrange(starts, stops)\n",
    "        array([3, 4, 4, 5, 6])\n",
    "\n",
    "    \"\"\"\n",
    "    stops = np.asarray(stops)\n",
    "    l = stops - starts # Lengths of each range.\n",
    "    return np.repeat(stops - l.cumsum(), l) + np.arange(l.sum())\n",
    "def latLongL2(original, secondary, k=4):\n",
    "    o_lat = original[:,1]\n",
    "    o_long = original[:,0]\n",
    "    s_lat = secondary[:,1]\n",
    "    s_long = secondary[:,0]\n",
    "    \n",
    "    diffs = (o_lat[:, None] - s_lat[None, :])**2 + (o_long[:, None] - s_long[None, :])**2\n",
    "    indices = np.argpartition(diffs, k, axis=1)[:, :k]\n",
    "    return indices\n",
    "# ugly ones from me\n",
    "def find_nearest(array, value): # finds closest value\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "def square(list): # squares something in a list because it wasn't working for me\n",
    "    return [i ** 2 for i in list]\n",
    "def squared(list):\n",
    "    return [i ** 1/2 for i in list]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MERRA2 INPUT VARIABLES: time, lon, lat, QV10M, T10M, TSKINWTR, U10, V10, EFLUXWTR, HFLUXWTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start MERRA2 import for 2017\n",
      "completed MERRA2 2017 import: 6.33 s\n"
     ]
    }
   ],
   "source": [
    "# 2017 data import and organization\n",
    "\n",
    "# let's do the entire thing by year. this way, we can just copy, paste, and adjust with year.\n",
    "# also makes naming variables easier lol\n",
    "\n",
    "sd = pd.read_csv('/Users/subhatrasivam/Documents/Internships/NOAA/Code/Saildrone/SD2017M2avghr.csv')\n",
    "time_sd = sd['hours'].values\n",
    "lon_sd = sd['lon'].values\n",
    "lat_sd = sd['lat'].values\n",
    "\n",
    "print('start MERRA2 import for 2017')\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "filename_prod = '/Users/subhatrasivam/Documents/Internships/NOAA/Code/MERRA2/MERRA2_2017.nc'\n",
    "f = nc.Dataset(filename_prod,mode='r')\n",
    "time_prod = f.variables['time'][:] # hours since 05/01/2017 00:30:00\n",
    "lon_prod = f.variables['lon'][:] # degrees\n",
    "lat_prod = f.variables['lat'][:] # degrees\n",
    "q_prod = f.variables['QV10M'][:] # kg/kg\n",
    "airtemp_prod = f.variables['T10M'][:] # K\n",
    "skntemp_prod = f.variables['TSKINWTR'][:] # K\n",
    "uwind_prod = f.variables['U10M'][:] # m*s^-1\n",
    "vwind_prod = f.variables['V10M'][:] # m*s^-1\n",
    "eflux_prod = f.variables['EFLUXWTR'][:] # W*m^-2\n",
    "hflux_prod = f.variables['HFLUXWTR'][:] # W*m^-2\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "delt = str(\"{:.2f}\".format(t1-t0))\n",
    "\n",
    "print('completed MERRA2 2017 import: ' + delt +' s')\n",
    "\n",
    "filepath = '/Users/subhatrasivam/Documents/Internships/NOAA/Code/MERRA2/2017MERRA2interp.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start MERRA2 import for 2018\n",
      "completed MERRA2 2018 import: 5.80 s\n"
     ]
    }
   ],
   "source": [
    "# 2018 data import and organization\n",
    "\n",
    "sd = pd.read_csv('/Users/subhatrasivam/Documents/Internships/NOAA/Code/Saildrone/SD2018M2avghr.csv')\n",
    "time_sd = sd['hours'].values\n",
    "lon_sd = sd['lon'].values\n",
    "lat_sd = sd['lat'].values\n",
    "\n",
    "print('start MERRA2 import for 2018')\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "filename_prod = '/Users/subhatrasivam/Documents/Internships/NOAA/Code/MERRA2/MERRA2_2018.nc'\n",
    "f = nc.Dataset(filename_prod,mode='r')\n",
    "time_prod = f.variables['time'][:] # hours since 05/01/2018 00:30:00\n",
    "lon_prod = f.variables['lon'][:] # degrees\n",
    "lat_prod = f.variables['lat'][:] # degrees\n",
    "q_prod = f.variables['QV10M'][:] # kg/kg\n",
    "airtemp_prod = f.variables['T10M'][:] # K\n",
    "skntemp_prod = f.variables['TSKINWTR'][:] # K\n",
    "uwind_prod = f.variables['U10M'][:] # m*s^-1\n",
    "vwind_prod = f.variables['V10M'][:] # m*s^-1\n",
    "eflux_prod = f.variables['EFLUXWTR'][:] # W*m^-2\n",
    "hflux_prod = f.variables['HFLUXWTR'][:] # W*m^-2\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "delt = str(\"{:.2f}\".format(t1-t0))\n",
    "\n",
    "print('completed MERRA2 2018 import: ' + delt +' s')\n",
    "\n",
    "filepath = '/Users/subhatrasivam/Documents/Internships/NOAA/Code/MERRA2/2018MERRA2interp.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start MERRA2 import for 2019\n",
      "completed MERRA2 2019 import: 6.09 s\n"
     ]
    }
   ],
   "source": [
    "# 2019 data import and organization\n",
    "\n",
    "sd = pd.read_csv('/Users/subhatrasivam/Documents/Internships/NOAA/Code/Saildrone/SD2019M2avghr.csv')\n",
    "time_sd = sd['hours'].values\n",
    "lon_sd = sd['lon'].values\n",
    "lat_sd = sd['lat'].values\n",
    "\n",
    "print('start MERRA2 import for 2019')\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "filename_prod = '/Users/subhatrasivam/Documents/Internships/NOAA/Code/MERRA2/MERRA2_2019.nc'\n",
    "f = nc.Dataset(filename_prod,mode='r')\n",
    "time_prod = f.variables['time'][:] # hours since 05/01/2019 00:30:00\n",
    "lon_prod = f.variables['lon'][:] # degrees\n",
    "lat_prod = f.variables['lat'][:] # degrees\n",
    "q_prod = f.variables['QV10M'][:] # kg/kg\n",
    "airtemp_prod = f.variables['T10M'][:] # K\n",
    "skntemp_prod = f.variables['TSKINWTR'][:] # K\n",
    "uwind_prod = f.variables['U10M'][:] # m*s^-1\n",
    "vwind_prod = f.variables['V10M'][:] # m*s^-1\n",
    "eflux_prod = f.variables['EFLUXWTR'][:] # W*m^-2\n",
    "hflux_prod = f.variables['HFLUXWTR'][:] # W*m^-2\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "delt = str(\"{:.2f}\".format(t1-t0))\n",
    "\n",
    "print('completed MERRA2 2019 import: ' + delt +' s')\n",
    "\n",
    "filepath = '/Users/subhatrasivam/Documents/Internships/NOAA/Code/MERRA2/2019MERRA2interp.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organized times: 4.08 s\n",
      "get inverse distance weights: 1.01 s\n",
      "get interpolated values: 15.05 s\n",
      "get 4 closest variable values: 2.83 s\n",
      "calculated variables: 0.02 s\n"
     ]
    }
   ],
   "source": [
    "# interpolation and calculations\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "# organize coordinates\n",
    "location_sd = np.stack((lon_sd,lat_sd),axis=1) # set saildrone coordinates\n",
    "\n",
    "gridlocation = [] # set MERRA2 coordinates\n",
    "grididx = []\n",
    "for idx_lon, lon in enumerate(lon_prod):\n",
    "    for idx_lat,lat in enumerate(lat_prod):\n",
    "        gridlocation.append([lon,lat])\n",
    "        grididx.append([idx_lon,idx_lat])\n",
    "gridlocation = np.asarray(gridlocation)\n",
    "grididx = np.asarray(grididx)\n",
    "\n",
    "close4 = latLongL2(location_sd,gridlocation)\n",
    "\n",
    "# organize times\n",
    "[idx_prod,idx_sd] = solution(time_prod,time_sd)\n",
    "idx_prod = np.array(idx_prod)\n",
    "timeidx_prod = np.copy(time_prod[idx_prod])\n",
    "efluxidx_prod = np.copy(eflux_prod[idx_prod])\n",
    "hfluxidx_prod = np.copy(hflux_prod[idx_prod])\n",
    "airtempidx_prod = np.copy(airtemp_prod[idx_prod])\n",
    "skntempidx_prod = np.copy(skntemp_prod[idx_prod])\n",
    "qidx_prod = np.copy(q_prod[idx_prod])\n",
    "uwindidx_prod = np.copy(uwind_prod[idx_prod])\n",
    "vwindidx_prod = np.copy(vwind_prod[idx_prod])\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "delt = str(\"{:.2f}\".format(t1-t0))\n",
    "\n",
    "print('organized times: ' + delt +' s')\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "# get distance estimations for MERRA2 (haversine)\n",
    "percentdist = []\n",
    "for grid_idx, point in enumerate(location_sd):\n",
    "    ind_close4 = close4[grid_idx]\n",
    "    ind_gridlocations = []\n",
    "    distancegrid = []\n",
    "    for ind in ind_close4:\n",
    "        gridpoint = gridlocation[ind]\n",
    "        ind_gridlocations.append(gridpoint)\n",
    "        lata, lona, latb, lonb, R = radians(gridpoint[1]),radians(gridpoint[0]), radians(point[1]), radians(point[0]), 6378.0\n",
    "        lat_diff = latb-lata\n",
    "        lon_diff = lonb-lona\n",
    "        a = np.sin(lat_diff/2)**2+np.cos(latb)*np.cos(lata)*np.sin(lon_diff/2)**2\n",
    "        c = 2*np.arctan2(a**(1/2),(1-a)**(1/2))\n",
    "        distancepix = R * c\n",
    "        distancegrid.append(np.divide(1,distancepix))\n",
    "    sumdist = np.sum(distancegrid)\n",
    "    percentdist.append(distancegrid/sumdist)\n",
    "\n",
    "# get distance estimations for MERRA2 (pixel distance formula)\n",
    "\"\"\"\n",
    "percentdist = []\n",
    "for grid_idx, point in enumerate(location_sd):\n",
    "    ind_close4 = close4[grid_idx]\n",
    "    ind_gridlocations = []\n",
    "    distancegrid = []\n",
    "    for ind in ind_close4:\n",
    "        gridpoint = gridlocation[ind]\n",
    "        ind_gridlocations.append(gridpoint)\n",
    "        distancepix = ((point[0] - gridpoint[0])**2 + (point[1] - gridpoint[1])**2)**1/2\n",
    "        distancegrid.append(np.divide(1,distancepix))\n",
    "    sumdist = np.sum(distancegrid)\n",
    "    percentdist.append(distancegrid/sumdist)\n",
    "\"\"\"\n",
    "\n",
    "percentdist = np.array(percentdist)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "delt = str(\"{:.2f}\".format(t1-t0))\n",
    "\n",
    "print('get inverse distance weights: ' + delt +' s')\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "# interpolate MERRA2 variables\n",
    "eflux_prod_withsd = []\n",
    "hflux_prod_withsd = []\n",
    "airtemp_prod_withsd = []\n",
    "q_prod_withsd = []\n",
    "skntemp_prod_withsd = []\n",
    "uwind_prod_withsd = []\n",
    "vwind_prod_withsd = []\n",
    "\n",
    "for time_s in time_sd:\n",
    "    for idx_time,time_m in enumerate(timeidx_prod):\n",
    "        if time_s == time_m:\n",
    "            eflux_prod_withsd.append(efluxidx_prod[idx_time])\n",
    "            hflux_prod_withsd.append(hfluxidx_prod[idx_time])\n",
    "            airtemp_prod_withsd.append(airtempidx_prod[idx_time])\n",
    "            q_prod_withsd.append(qidx_prod[idx_time])\n",
    "            skntemp_prod_withsd.append(skntempidx_prod[idx_time])\n",
    "            uwind_prod_withsd.append(uwindidx_prod[idx_time])\n",
    "            vwind_prod_withsd.append(vwindidx_prod[idx_time])\n",
    "eflux_prod_withsd = np.array(eflux_prod_withsd)\n",
    "hflux_prod_withsd = np.array(hflux_prod_withsd)\n",
    "airtemp_prod_withsd = np.array(airtemp_prod_withsd)\n",
    "q_prod_withsd = np.array(q_prod_withsd)\n",
    "skntemp_prod_withsd = np.array(skntemp_prod_withsd)\n",
    "uwind_prod_withsd = np.array(uwind_prod_withsd)\n",
    "vwind_prod_withsd = np.array(vwind_prod_withsd)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "delt = str(\"{:.2f}\".format(t1-t0))\n",
    "\n",
    "print('get interpolated values: ' + delt +' s')\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "# get 4 closest grid points\n",
    "timeidx = np.arange(0,len(time_sd),1)\n",
    "lat1 = []\n",
    "lat2 = []\n",
    "lat3 = []\n",
    "lat4 = []\n",
    "lon1 = []\n",
    "lon2 = []\n",
    "lon3 = []\n",
    "lon4 = []\n",
    "\n",
    "for k in close4:\n",
    "    lat1.append(gridlocation[k[0]][1])\n",
    "    lon1.append(gridlocation[k[0]][0])\n",
    "    lat2.append(gridlocation[k[1]][1])\n",
    "    lon2.append(gridlocation[k[1]][0])\n",
    "    lat3.append(gridlocation[k[2]][1])\n",
    "    lon3.append(gridlocation[k[2]][0])\n",
    "    lat4.append(gridlocation[k[3]][1])\n",
    "    lon4.append(gridlocation[k[3]][0])\n",
    "\n",
    "arraylon1 = []\n",
    "arraylon2 = []\n",
    "arraylon3 = []\n",
    "arraylon4 = []\n",
    "arraylat1 = []\n",
    "arraylat2 = []\n",
    "arraylat3 = []\n",
    "arraylat4 = []\n",
    "\n",
    "for idx,lon in enumerate(lon1):\n",
    "    arraylon1.append(find_nearest(lon_prod,lon))\n",
    "    arraylon2.append(find_nearest(lon_prod,lon2[idx]))\n",
    "    arraylon3.append(find_nearest(lon_prod,lon3[idx]))\n",
    "    arraylon4.append(find_nearest(lon_prod,lon4[idx]))\n",
    "    arraylat1.append(find_nearest(lat_prod,lat1[idx]))\n",
    "    arraylat2.append(find_nearest(lat_prod,lat2[idx]))\n",
    "    arraylat3.append(find_nearest(lat_prod,lat3[idx]))\n",
    "    arraylat4.append(find_nearest(lat_prod,lat4[idx]))  \n",
    "\n",
    "latlon1 = np.stack((arraylat1,arraylon1),axis=1)\n",
    "latlon2 = np.stack((arraylat2,arraylon2),axis=1)   \n",
    "latlon3 = np.stack((arraylat3,arraylon3),axis=1)   \n",
    "latlon4 = np.stack((arraylat4,arraylon4),axis=1)\n",
    "\n",
    "timeidx = np.arange(0,len(time_sd),1)\n",
    "\n",
    "efluxlatlon1 = []\n",
    "hfluxlatlon1 = []\n",
    "qlatlon1 = []\n",
    "airtemplatlon1 = []\n",
    "skntemplatlot1 = []\n",
    "uwindtemplatlot1 = []\n",
    "vwindtemplatlot1 = []\n",
    "\n",
    "efluxlatlon2 = []\n",
    "hfluxlatlon2 = []\n",
    "qlatlon2 = []\n",
    "airtemplatlon2 = []\n",
    "skntemplatlot2 = []\n",
    "uwindtemplatlot2 = []\n",
    "vwindtemplatlot2 = []\n",
    "\n",
    "efluxlatlon3 = []\n",
    "hfluxlatlon3 = []\n",
    "qlatlon3 = []\n",
    "airtemplatlon3 = []\n",
    "skntemplatlot3 = []\n",
    "uwindtemplatlot3 = []\n",
    "vwindtemplatlot3 = []\n",
    "\n",
    "efluxlatlon4 = []\n",
    "hfluxlatlon4 = []\n",
    "qlatlon4 = []\n",
    "airtemplatlon4 = []\n",
    "skntemplatlot4 = []\n",
    "uwindtemplatlot4 = []\n",
    "vwindtemplatlot4 = []\n",
    "\n",
    "for j in timeidx:\n",
    "    # first closest\n",
    "    efluxlatlon1.append(eflux_prod_withsd[j,latlon1[j,0],latlon1[j,1]])\n",
    "    hfluxlatlon1.append(hflux_prod_withsd[j,latlon1[j,0],latlon1[j,1]])\n",
    "    qlatlon1.append(q_prod_withsd[j,latlon1[j,0],latlon1[j,1]])\n",
    "    airtemplatlon1.append(airtemp_prod_withsd[j,latlon1[j,0],latlon1[j,1]])\n",
    "    skntemplatlot1.append(skntemp_prod_withsd[j,latlon1[j,0],latlon1[j,1]])\n",
    "    uwindtemplatlot1.append(uwind_prod_withsd[j,latlon1[j,0],latlon1[j,1]])\n",
    "    vwindtemplatlot1.append(vwind_prod_withsd[j,latlon1[j,0],latlon1[j,1]])\n",
    "    # second closest\n",
    "    efluxlatlon2.append(eflux_prod_withsd[j,latlon2[j,0],latlon2[j,1]])\n",
    "    hfluxlatlon2.append(hflux_prod_withsd[j,latlon2[j,0],latlon2[j,1]])\n",
    "    qlatlon2.append(q_prod_withsd[j,latlon2[j,0],latlon2[j,1]])\n",
    "    airtemplatlon2.append(airtemp_prod_withsd[j,latlon2[j,0],latlon2[j,1]])\n",
    "    skntemplatlot2.append(skntemp_prod_withsd[j,latlon2[j,0],latlon2[j,1]])\n",
    "    uwindtemplatlot2.append(uwind_prod_withsd[j,latlon2[j,0],latlon2[j,1]])\n",
    "    vwindtemplatlot2.append(vwind_prod_withsd[j,latlon2[j,0],latlon2[j,1]])\n",
    "    # third closest\n",
    "    efluxlatlon3.append(eflux_prod_withsd[j,latlon3[j,0],latlon3[j,1]])\n",
    "    hfluxlatlon3.append(hflux_prod_withsd[j,latlon3[j,0],latlon3[j,1]])\n",
    "    qlatlon3.append(q_prod_withsd[j,latlon3[j,0],latlon3[j,1]])\n",
    "    airtemplatlon3.append(airtemp_prod_withsd[j,latlon3[j,0],latlon3[j,1]])\n",
    "    skntemplatlot3.append(skntemp_prod_withsd[j,latlon3[j,0],latlon3[j,1]])\n",
    "    uwindtemplatlot3.append(uwind_prod_withsd[j,latlon3[j,0],latlon3[j,1]])\n",
    "    vwindtemplatlot3.append(vwind_prod_withsd[j,latlon3[j,0],latlon3[j,1]])\n",
    "    # furthest\n",
    "    efluxlatlon4.append(eflux_prod_withsd[j,latlon4[j,0],latlon4[j,1]])\n",
    "    hfluxlatlon4.append(hflux_prod_withsd[j,latlon4[j,0],latlon4[j,1]])\n",
    "    qlatlon4.append(q_prod_withsd[j,latlon4[j,0],latlon4[j,1]])\n",
    "    airtemplatlon4.append(airtemp_prod_withsd[j,latlon4[j,0],latlon4[j,1]])\n",
    "    skntemplatlot4.append(skntemp_prod_withsd[j,latlon4[j,0],latlon4[j,1]])\n",
    "    uwindtemplatlot4.append(uwind_prod_withsd[j,latlon4[j,0],latlon4[j,1]])\n",
    "    vwindtemplatlot4.append(vwind_prod_withsd[j,latlon4[j,0],latlon4[j,1]])\n",
    "\n",
    "for_df = np.array([timeidx,efluxlatlon1,hfluxlatlon1,airtemplatlon1,skntemplatlot1,qlatlon1,uwindtemplatlot1,vwindtemplatlot1,percentdist[:,0]])\n",
    "for_df = for_df.T\n",
    "for_df = np.ma.masked_where(for_df == 999999986991104, for_df)\n",
    "for_df = np.ma.compress_rows(for_df)\n",
    "df = pd.DataFrame(for_df, columns=['time','eflux','hflux','airtemp','skntemp','q','uwind','vwind','percent'])\n",
    "\n",
    "time1 = df['time']\n",
    "efluxlatlon1 = df['eflux'].values\n",
    "hfluxlatlon1 = df['hflux'].values\n",
    "airtemplatlon1 = df['airtemp'].values\n",
    "skntemplatlot1 = df['skntemp'].values\n",
    "qlatlon1 = df['q'].values\n",
    "uwindtemplatlot1 = df['uwind'].values\n",
    "vwindtemplatlot1 = df['vwind'].values\n",
    "percent1 = df['percent'].values\n",
    "\n",
    "efluxlatlon1 = np.array(efluxlatlon1)\n",
    "hfluxlatlon1 = np.array(hfluxlatlon1)\n",
    "qlatlon1 = np.array(qlatlon1)\n",
    "airtemplatlon1 = np.array(airtemplatlon1)\n",
    "skntemplatlot1 = np.array(skntemplatlot1)\n",
    "uwindtemplatlot1 = np.array(uwindtemplatlot1)\n",
    "vwindtemplatlot1 = np.array(vwindtemplatlot1)\n",
    "percent1 = np.array(percent1)\n",
    "\n",
    "for_df = np.array([timeidx,efluxlatlon2,hfluxlatlon2,airtemplatlon2,skntemplatlot2,qlatlon2,uwindtemplatlot2,vwindtemplatlot2,percentdist[:,1]])\n",
    "for_df = for_df.T\n",
    "for_df = np.ma.masked_where(for_df == 999999986991104, for_df)\n",
    "for_df = np.ma.compress_rows(for_df)\n",
    "df = pd.DataFrame(for_df, columns=['time','eflux','hflux','airtemp','skntemp','q','uwind','vwind','percent'])\n",
    "\n",
    "time2 = df['time']\n",
    "efluxlatlon2 = df['eflux'].values\n",
    "hfluxlatlon2 = df['hflux'].values\n",
    "airtemplatlon2 = df['airtemp'].values\n",
    "skntemplatlot2 = df['skntemp'].values\n",
    "qlatlon2 = df['q'].values\n",
    "uwindtemplatlot2 = df['uwind'].values\n",
    "vwindtemplatlot2 = df['vwind'].values\n",
    "percent2 = df['percent'].values\n",
    "\n",
    "efluxlatlon2 = np.array(efluxlatlon2)\n",
    "hfluxlatlon2 = np.array(hfluxlatlon2)\n",
    "qlatlon2 = np.array(qlatlon2)\n",
    "airtemplatlon2 = np.array(airtemplatlon2)\n",
    "skntemplatlot2 = np.array(skntemplatlot2)\n",
    "uwindtemplatlot2 = np.array(uwindtemplatlot2)\n",
    "vwindtemplatlot2 = np.array(vwindtemplatlot2)\n",
    "percent2 = np.array(percent2)\n",
    "\n",
    "for_df = np.array([timeidx,efluxlatlon3,hfluxlatlon3,airtemplatlon3,skntemplatlot3,qlatlon3,uwindtemplatlot3,vwindtemplatlot3,percentdist[:,2]])\n",
    "for_df = for_df.T\n",
    "for_df = np.ma.masked_where(for_df == 999999986991104, for_df)\n",
    "for_df = np.ma.compress_rows(for_df)\n",
    "df = pd.DataFrame(for_df, columns=['time','eflux','hflux','airtemp','skntemp','q','uwind','vwind','percent'])\n",
    "\n",
    "time3 = df['time']\n",
    "efluxlatlon3 = df['eflux'].values\n",
    "hfluxlatlon3 = df['hflux'].values\n",
    "airtemplatlon3 = df['airtemp'].values\n",
    "skntemplatlot3 = df['skntemp'].values\n",
    "qlatlon3 = df['q'].values\n",
    "uwindtemplatlot3 = df['uwind'].values\n",
    "vwindtemplatlot3 = df['vwind'].values\n",
    "percent3 = df['percent'].values\n",
    "\n",
    "efluxlatlon3 = np.array(efluxlatlon3)\n",
    "hfluxlatlon3 = np.array(hfluxlatlon3)\n",
    "qlatlon3 = np.array(qlatlon3)\n",
    "airtemplatlon3 = np.array(airtemplatlon3)\n",
    "skntemplatlot3 = np.array(skntemplatlot3)\n",
    "uwindtemplatlot3 = np.array(uwindtemplatlot3)\n",
    "vwindtemplatlot3 = np.array(vwindtemplatlot3)\n",
    "percent3 = np.array(percent3)\n",
    "\n",
    "for_df = np.array([time_sd,efluxlatlon4,hfluxlatlon4,airtemplatlon4,skntemplatlot4,qlatlon4,uwindtemplatlot4,vwindtemplatlot4,percentdist[:,3]])\n",
    "for_df = for_df.T\n",
    "for_df = np.ma.masked_where(for_df == 999999986991104, for_df)\n",
    "for_df = np.ma.compress_rows(for_df)\n",
    "df = pd.DataFrame(for_df, columns=['time','eflux','hflux','airtemp','skntemp','q','uwind','vwind','percent'])\n",
    "\n",
    "time_sd = df['time']\n",
    "efluxlatlon4 = df['eflux'].values\n",
    "hfluxlatlon4 = df['hflux'].values\n",
    "airtemplatlon4 = df['airtemp'].values\n",
    "skntemplatlot4 = df['skntemp'].values\n",
    "qlatlon4 = df['q'].values\n",
    "uwindtemplatlot4 = df['uwind'].values\n",
    "vwindtemplatlot4 = df['vwind'].values\n",
    "percent4 = df['percent'].values\n",
    "\n",
    "efluxlatlon4 = np.array(efluxlatlon4)\n",
    "hfluxlatlon4 = np.array(hfluxlatlon4)\n",
    "qlatlon4 = np.array(qlatlon4)\n",
    "airtemplatlon4 = np.array(airtemplatlon4)\n",
    "skntemplatlot4 = np.array(skntemplatlot4)\n",
    "uwindtemplatlot4 = np.array(uwindtemplatlot4)\n",
    "vwindtemplatlot4 = np.array(vwindtemplatlot4)\n",
    "percent4 = np.array(percent4)\n",
    "\n",
    "# next step is to get rid of everything(!) that has a NAN values for all four values. makes sense in my head sorry to whoever is reading this\n",
    "# we already got rid of NAN valules per the four, but now it is a matter of getting rid of all of it\n",
    "# ok we are actually good on time for 2017!!! this may be a coincidence and we need to fix this for ERA5. but i checked the data and we are good baby\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "delt = str(\"{:.2f}\".format(t1-t0))\n",
    "\n",
    "print('get 4 closest variable values: ' + delt +' s')\n",
    "\n",
    "# get weighted average\n",
    "eflux = efluxlatlon1*percent1 + efluxlatlon2*percent2 + efluxlatlon3*percent3 + efluxlatlon4*percent4\n",
    "hflux = hfluxlatlon1*percent1 + hfluxlatlon2*percent2 + hfluxlatlon3*percent3 + hfluxlatlon4*percent4\n",
    "airtemp = airtemplatlon1*percent1 + airtemplatlon2*percent2 + airtemplatlon3*percent3 + airtemplatlon4*percent4\n",
    "skntemp = skntemplatlot1*percent1 + skntemplatlot2*percent2 + skntemplatlot3*percent3 + skntemplatlot4*percent4\n",
    "q = qlatlon1*percent1 + qlatlon2*percent2 + qlatlon3*percent3 + qlatlon4*percent4\n",
    "uwind = uwindtemplatlot1*percent1 + uwindtemplatlot2*percent2 + uwindtemplatlot3*percent3 + uwindtemplatlot4*percent4\n",
    "vwind = vwindtemplatlot1*percent1 + vwindtemplatlot2*percent2 + vwindtemplatlot3*percent3 + vwindtemplatlot4*percent4\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "# calculate variables\n",
    "airtemp = np.array(np.subtract(airtemp,273.15)) # K -> C\n",
    "skntemp = np.array(np.subtract(skntemp,273.15)) # K -> C\n",
    "\n",
    "def square(list):\n",
    "    return [i ** 2 for i in list]\n",
    "def squared(list):\n",
    "    return [i ** 1/2 for i in list]\n",
    "usq = square(uwind)\n",
    "vsq = square(vwind)\n",
    "sum  = np.add(usq,vsq)\n",
    "windidx_prod = squared(sum) # u and v -> total magnitude\n",
    "wind = np.array(windidx_prod)\n",
    "\n",
    "es_tempfin_prod = 6.11*2.71828**(5420*(1/273-1/(airtemp+273.15))) # air saturation vapor pressure OK\n",
    "es_sknfin_prod = 6.11*2.71828**(5420*(1/273-1/(skntemp+273.15))) # sea saturation vapor pressure OK\n",
    "\n",
    "rat_prh = 0.622*es_tempfin_prod*((q+1)/q) #mb/rh dec\n",
    "\n",
    "qskn = 1000*311*es_sknfin_prod/(500*rat_prh-311*es_sknfin_prod)\n",
    "qair = np.multiply(q,1000) # kg/kg -> g/kg\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "delt = str(\"{:.2f}\".format(t1-t0))\n",
    "\n",
    "print('calculated variables: ' + delt +' s')\n",
    "\n",
    "for_df = np.stack([time_sd,eflux,hflux,qair,qskn,airtemp,skntemp,wind],axis=1)\n",
    "df = pd.DataFrame(for_df,columns=['time','eflux','hflux','qair','qskn','airtemp','skntemp','wind'])\n",
    "df.to_csv(filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arctic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
