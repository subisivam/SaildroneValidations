{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "### 2019 ###\n",
    "############\n",
    "\n",
    "# written by Subhatra Sivam: ssivam@terpmail.umd.edu\n",
    "# took me 19.6 seconds to run #\n",
    "\n",
    "# import python packages\n",
    "import cartopy.crs as ccrs\n",
    "from datetime import datetime\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# collect all saildrone data\n",
    "sdfull = []\n",
    "\n",
    "# set saildrone color :)\n",
    "sdcolor = '#eb633e'\n",
    "\n",
    "# loop through saildrones\n",
    "sdname = ['1033','1034','1035','1036','1037','1041']\n",
    "for name in sdname:\n",
    "    # load flux data\n",
    "    filepath = 'raw-data/sd/flux/sd2019-' + name + '.csv'\n",
    "    sd = pd.read_csv(filepath)\n",
    "    \n",
    "    # store and remove unit row\n",
    "    units = sd.iloc[0,:]\n",
    "    sdid = sd['ID'][1]\n",
    "    sd = sd.iloc[1:,1:]\n",
    "\n",
    "    # get saildrone locations\n",
    "    lon0 = sd['longitude'].values\n",
    "    lat0 = sd['latitude'].values\n",
    "    lon = []\n",
    "    for l in lon0:\n",
    "        lon.append(float(l))\n",
    "    sd['longitude'] = lon\n",
    "    lat = []\n",
    "    for l in lat0:\n",
    "        lat.append(float(l))\n",
    "    sd['latitude'] = lat\n",
    "    \n",
    "    ### uncomment below for trajectory maps ###\n",
    "    # # set axis dimensions\n",
    "    # plt.figure()\n",
    "    # ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    # fname = os.path.join('/Users/ssiv/Documents/', 'clean-geo-base.png')\n",
    "    # ax.imshow(imread(fname), origin='upper', transform=ccrs.PlateCarree(), \n",
    "    #         extent=[-180, 180, -90, 90])\n",
    "    # ax.set_extent([-180, -145, 50, 80], crs=ccrs.PlateCarree())\n",
    "    # ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False,\n",
    "    #                 linewidth=1, color='k', alpha=0.5)\n",
    "\n",
    "    # # plot locations\n",
    "    # plt.scatter(lon,lat,transform=ccrs.Geodetic(),s=1,c=sdcolor)\n",
    "    # plt.title(sdid)\n",
    "    # path = 'maps/sd-track/' + sdid + '.png'\n",
    "    # plt.savefig(path)\n",
    "\n",
    "    # assessing time\n",
    "    date0 = sd['time']\n",
    "    date = []\n",
    "    for d in date0:\n",
    "        date_object = datetime.strptime(d,'%Y-%m-%dT%H:%M:%SZ')\n",
    "        date.append(date_object)\n",
    "    sd['time'] = date\n",
    "\n",
    "    # extract the date and hour from the 'datetime' column\n",
    "    sd['date'] = sd['time'].dt.date\n",
    "    sd['hour'] = sd['time'].dt.hour\n",
    "\n",
    "    # group the DataFrame by 'date' and 'hour' and calculate the mean for each group\n",
    "    # this ignores NaN values\n",
    "    lon = sd.groupby(['date', 'hour'])['longitude'].mean().reset_index()\n",
    "    lat = sd.groupby(['date', 'hour'])['latitude'].mean().reset_index()\n",
    "    sd['QL'] = pd.to_numeric(sd['QL'], errors='coerce') \n",
    "    QL = sd.groupby(['date', 'hour'])['QL'].mean().reset_index()\n",
    "    sd['QS'] = pd.to_numeric(sd['QS'], errors='coerce') \n",
    "    QS = sd.groupby(['date', 'hour'])['QS'].mean().reset_index()\n",
    "    sd = pd.DataFrame([lon['date'],lon['hour'],lon['longitude'],lat['latitude'],QL['QL'],QS['QS']])\n",
    "    sdflux = sd.T\n",
    "\n",
    "    # load observation data\n",
    "    filepath = 'raw-data/sd/obs/sd2019-' + name + '.csv'\n",
    "    sd = pd.read_csv(filepath,low_memory=False)\n",
    "    units = sd.iloc[0,:]\n",
    "    sdid = sd['trajectory'][1]\n",
    "    sd = sd.iloc[1:,1:]\n",
    "\n",
    "    # assessing time\n",
    "    date0 = sd['time']\n",
    "    date = []\n",
    "    for d in date0:\n",
    "        date_object = datetime.strptime(d,'%Y-%m-%dT%H:%M:%SZ')\n",
    "        date.append(date_object)\n",
    "    sd['time'] = date\n",
    "\n",
    "    # extract the date and hour from the 'datetime' column\n",
    "    sd['date'] = sd['time'].dt.date\n",
    "    sd['hour'] = sd['time'].dt.hour\n",
    "\n",
    "    # group the DataFrame by 'date' and 'hour' and calculate the mean for each group\n",
    "    # this ignores NaN values\n",
    "    sd['T'] = pd.to_numeric(sd['TEMP_AIR_MEAN'], errors='coerce') \n",
    "    T = sd.groupby(['date', 'hour'])['T'].mean().reset_index()\n",
    "    sd['SST'] = pd.to_numeric(sd['TEMP_CTD_RBR_MEAN'], errors='coerce') \n",
    "    SST = sd.groupby(['date', 'hour'])['SST'].mean().reset_index()\n",
    "    sd['RH'] = pd.to_numeric(sd['RH_MEAN'], errors='coerce')\n",
    "    RH = sd.groupby(['date', 'hour'])['RH'].mean().reset_index()\n",
    "    sd['V'] = pd.to_numeric(sd['wind_speed'], errors='coerce')\n",
    "    V = sd.groupby(['date', 'hour'])['V'].mean().reset_index()\n",
    "    sd['p'] = pd.to_numeric(sd['BARO_PRES_MEAN'], errors='coerce')\n",
    "    p = sd.groupby(['date', 'hour'])['p'].mean().reset_index()\n",
    "    sd = pd.DataFrame([T['date'],T['hour'],T['T'],SST['SST'],RH['RH'],V['V']])\n",
    "    sdobs = sd.T\n",
    "    \n",
    "    # merge data\n",
    "    sd = pd.merge(sdflux, sdobs, on=['date', 'hour'], how='inner')\n",
    "    if name == sdname[0]:\n",
    "        sdfull = sd\n",
    "    else:\n",
    "        sdfull = pd.concat([sdfull,sd])\n",
    "\n",
    "# convert 'date' and 'hour' columns to strings\n",
    "sdfull['date'] = sdfull['date'].astype(str)\n",
    "sdfull['hour'] = sdfull['hour'].astype(int).astype(str)\n",
    "\n",
    "# concatenate 'date' and 'hour' columns with a space in between\n",
    "sdfull['datetime'] = sdfull['date'] + ' ' + sdfull['hour'] + ':30:00'\n",
    "\n",
    "# convert the concatenated column to datetime\n",
    "sdfull['datetime'] = pd.to_datetime(sdfull['datetime'])\n",
    "sdfull['datetime'] = sdfull['datetime'].apply(lambda x: x.timestamp())\n",
    "\n",
    "# drop the 'date' and 'hour' columns\n",
    "sdfull.drop(['date', 'hour'], axis=1, inplace=True)\n",
    "sdfull.dropna(inplace=True)\n",
    "\n",
    "# save file\n",
    "sdfull.to_csv('data/sd/avg-at30-2019.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "### 2018 ###\n",
    "############\n",
    "\n",
    "# written by Subhatra Sivam: ssivam@terpmail.umd.edu\n",
    "# took me 8.4 seconds to run #\n",
    "\n",
    "# import python packages\n",
    "import cartopy.crs as ccrs\n",
    "from datetime import datetime\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# collect all saildrone data\n",
    "sdfull = []\n",
    "\n",
    "# set saildrone color :)\n",
    "sdcolor = '#eb633e'\n",
    "\n",
    "# loop through saildrones\n",
    "sdname = ['1020','1021','1022','1023']\n",
    "for name in sdname:\n",
    "    # load flux data\n",
    "    filepath = 'raw-data/sd/flux/sd2018-' + name + '.csv'\n",
    "    sd = pd.read_csv(filepath)\n",
    "\n",
    "    # store and remove unit row\n",
    "    units = sd.iloc[0,:]\n",
    "    sdid = sd['ID'][1]\n",
    "    sd = sd.iloc[1:,1:]\n",
    "\n",
    "    # get saildrone locations\n",
    "    lon0 = sd['longitude'].values\n",
    "    lat0 = sd['latitude'].values\n",
    "    lon = []\n",
    "    for l in lon0:\n",
    "        lon.append(float(l))\n",
    "    sd['longitude'] = lon\n",
    "    lat = []\n",
    "    for l in lat0:\n",
    "        lat.append(float(l))\n",
    "    sd['latitude'] = lat\n",
    "\n",
    "    ### uncomment below for trajectory maps ###\n",
    "    # # set axis dimensions\n",
    "    # plt.figure()\n",
    "    # ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    # fname = os.path.join('/Users/ssiv/Documents/', 'clean-geo-base.png')\n",
    "    # ax.imshow(imread(fname), origin='upper', transform=ccrs.PlateCarree(), \n",
    "    #         extent=[-180, 180, -90, 90])\n",
    "    # ax.set_extent([-180, -145, 50, 80], crs=ccrs.PlateCarree())\n",
    "    # ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False,\n",
    "    #                 linewidth=1, color='k', alpha=0.5)\n",
    "\n",
    "    # # plot locations\n",
    "    # plt.scatter(lon,lat,transform=ccrs.Geodetic(),s=1,c=sdcolor)\n",
    "    # plt.title(sdid)\n",
    "    # path = 'maps/sd-track/' + sdid + '.png'\n",
    "    # plt.savefig(path)\n",
    "\n",
    "    # assessing time\n",
    "    date0 = sd['time']\n",
    "    date = []\n",
    "    for d in date0:\n",
    "        date_object = datetime.strptime(d,'%Y-%m-%dT%H:%M:%SZ')\n",
    "        date.append(date_object)\n",
    "    sd['time'] = date\n",
    "\n",
    "    # extract the date and hour from the 'datetime' column\n",
    "    sd['date'] = sd['time'].dt.date\n",
    "    sd['hour'] = sd['time'].dt.hour\n",
    "\n",
    "    # group the DataFrame by 'date' and 'hour' and calculate the mean for each group\n",
    "    # this ignores NaN values\n",
    "    lon = sd.groupby(['date', 'hour'])['longitude'].mean().reset_index()\n",
    "    lat = sd.groupby(['date', 'hour'])['latitude'].mean().reset_index()\n",
    "    sd['QL'] = pd.to_numeric(sd['QL'], errors='coerce') \n",
    "    QL = sd.groupby(['date', 'hour'])['QL'].mean().reset_index()\n",
    "    sd['QS'] = pd.to_numeric(sd['QS'], errors='coerce') \n",
    "    QS = sd.groupby(['date', 'hour'])['QS'].mean().reset_index()\n",
    "    sd = pd.DataFrame([lon['date'],lon['hour'],lon['longitude'],lat['latitude'],QL['QL'],QS['QS']])\n",
    "    sdflux = sd.T\n",
    "\n",
    "    # load observation data\n",
    "    filepath = 'raw-data/sd/obs/sd2018-' + name + '.csv'\n",
    "    sd = pd.read_csv(filepath,low_memory=False)\n",
    "    units = sd.iloc[0,:]\n",
    "    sdid = sd['trajectory'][1]\n",
    "    sd = sd.iloc[1:,1:]\n",
    "\n",
    "    # assessing time\n",
    "    date0 = sd['time']\n",
    "    date = []\n",
    "    for d in date0:\n",
    "        date_object = datetime.strptime(d,'%Y-%m-%dT%H:%M:%SZ')\n",
    "        date.append(date_object)\n",
    "    sd['time'] = date\n",
    "\n",
    "    # extract the date and hour from the 'datetime' column\n",
    "    sd['date'] = sd['time'].dt.date\n",
    "    sd['hour'] = sd['time'].dt.hour\n",
    "\n",
    "    # group the DataFrame by 'date' and 'hour' and calculate the mean for each group\n",
    "    # this ignores NaN values\n",
    "    sd['T'] = pd.to_numeric(sd['TEMP_AIR_MEAN'], errors='coerce') \n",
    "    T = sd.groupby(['date', 'hour'])['T'].mean().reset_index()\n",
    "    sd['SST'] = pd.to_numeric(sd['TEMP_CTD_MEAN'], errors='coerce') \n",
    "    SST = sd.groupby(['date', 'hour'])['SST'].mean().reset_index()\n",
    "    sd['RH'] = pd.to_numeric(sd['RH_MEAN'], errors='coerce')\n",
    "    RH = sd.groupby(['date', 'hour'])['RH'].mean().reset_index()\n",
    "    sd['V'] = pd.to_numeric(sd['wind_speed'], errors='coerce')\n",
    "    V = sd.groupby(['date', 'hour'])['V'].mean().reset_index()\n",
    "    sd['p'] = pd.to_numeric(sd['BARO_PRES_MEAN'], errors='coerce')\n",
    "    p = sd.groupby(['date', 'hour'])['p'].mean().reset_index()\n",
    "\n",
    "    sd = pd.DataFrame([T['date'],T['hour'],T['T'],SST['SST'],RH['RH'],V['V'],p['p']])\n",
    "    sdobs = sd.T\n",
    "\n",
    "    # merge data\n",
    "    sd = pd.merge(sdflux, sdobs, on=['date', 'hour'], how='inner')\n",
    "    if name == sdname[0]:\n",
    "        sdfull = sd\n",
    "    else:\n",
    "        sdfull = pd.concat([sdfull,sd])\n",
    "\n",
    "# convert 'date' and 'hour' columns to strings\n",
    "sdfull['date'] = sdfull['date'].astype(str)\n",
    "sdfull['hour'] = sdfull['hour'].astype(int).astype(str)\n",
    "\n",
    "# concatenate 'date' and 'hour' columns with a space in between\n",
    "sdfull['datetime'] = sdfull['date'] + ' ' + sdfull['hour'] + ':30:00'\n",
    "\n",
    "# convert the concatenated column to datetime\n",
    "sdfull['datetime'] = pd.to_datetime(sdfull['datetime'])\n",
    "sdfull['datetime'] = sdfull['datetime'].apply(lambda x: x.timestamp())\n",
    "\n",
    "# drop the 'date' and 'hour' columns\n",
    "sdfull.drop(['date', 'hour'], axis=1, inplace=True)\n",
    "sdfull.dropna(inplace=True)\n",
    "\n",
    "# save file\n",
    "sdfull.to_csv('data/sd/avg-at30-2018.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "### 2017 ###\n",
    "############\n",
    "\n",
    "# written by Subhatra Sivam: ssivam@terpmail.umd.edu\n",
    "# took me 3.7 seconds to run #\n",
    "\n",
    "# import python packages\n",
    "import cartopy.crs as ccrs\n",
    "from datetime import datetime\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "# collect all saildrone data\n",
    "sdfull = []\n",
    "\n",
    "# set saildrone color :)\n",
    "sdcolor = '#eb633e'\n",
    "\n",
    "# read observation data\n",
    "filename = 'raw-data/sd/obs/sd2017.nc'\n",
    "f = nc.Dataset(filename,mode='r')\n",
    "time = f.variables['time'][:]\n",
    "time.astype(int) # some time values were decimals, when they should be integers\n",
    "lat = f.variables['latitude'][:]\n",
    "lon = f.variables['longitude'][:]\n",
    "p = f.variables['BARO_PRES_MEAN'][:]\n",
    "rh = f.variables['RH_MEAN'][:]\n",
    "sst = f.variables['TEMP_CTD_MEAN'][:]\n",
    "t = f.variables['TEMP_AIR_MEAN'][:]\n",
    "V = f.variables['wind_speed'][:]\n",
    "\n",
    "# identify local minima to separate saildrones\n",
    "localmin = np.array(argrelextrema(time, np.less))\n",
    "\n",
    "# create DataFrames for each saildrone subset\n",
    "def create_saildrone_df(time, lat, lon, sst, t, rh, V, p, start, end):\n",
    "    subset_df = pd.DataFrame({\n",
    "        'datetime': time[start:end].squeeze(),\n",
    "        'lat': lat[start:end].squeeze(),\n",
    "        'lon': lon[start:end].squeeze(),\n",
    "        'SST': sst[start:end].squeeze(),\n",
    "        'T': t[start:end].squeeze(),\n",
    "        'RH': rh[start:end].squeeze(),\n",
    "        'V': V[start:end].squeeze(),\n",
    "        'p': p[start:end].squeeze()\n",
    "    })\n",
    "    return subset_df\n",
    "\n",
    "# Create DataFrames for each saildrone subset\n",
    "sd1001 = create_saildrone_df(time, lat, lon, sst, t, rh, V, p, 0, localmin[0][0])\n",
    "sd1002 = create_saildrone_df(time, lat, lon, sst, t, rh, V, p, localmin[0][0], localmin[0][1])\n",
    "sd1003 = create_saildrone_df(time, lat, lon, sst, t, rh, V, p, localmin[0][1], len(time))\n",
    "\n",
    "# loop through saildrones\n",
    "sdname = ['1001','1002','1003']\n",
    "for idx2017, name in enumerate(sdname):\n",
    "    # load flux data\n",
    "    filepath = 'raw-data/sd/flux/sd2017-' + name + '.csv'\n",
    "    sd = pd.read_csv(filepath,low_memory=False)\n",
    "\n",
    "    # store and remove unit row\n",
    "    units = sd.iloc[0,:]\n",
    "    sdid = sd['ID'][1]\n",
    "    sd = sd.iloc[1:,1:]\n",
    "\n",
    "    # get saildrone locations\n",
    "    lon0 = sd['longitude'].values\n",
    "    lat0 = sd['latitude'].values\n",
    "    lon = []\n",
    "    for l in lon0:\n",
    "        lon.append(float(l))\n",
    "    sd['longitude'] = lon\n",
    "    lat = []\n",
    "    for l in lat0:\n",
    "        lat.append(float(l))\n",
    "    sd['latitude'] = lat\n",
    "\n",
    "    ### uncomment below for trajectory maps ###\n",
    "    # # set axis dimensions\n",
    "    # plt.figure()\n",
    "    # ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    # fname = os.path.join('/Users/ssiv/Documents/', 'clean-geo-base.png')\n",
    "    # ax.imshow(imread(fname), origin='upper', transform=ccrs.PlateCarree(), \n",
    "    #         extent=[-180, 180, -90, 90])\n",
    "    # ax.set_extent([-180, -145, 50, 80], crs=ccrs.PlateCarree())\n",
    "    # ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False,\n",
    "    #                 linewidth=1, color='k', alpha=0.5)\n",
    "\n",
    "    # # plot locations\n",
    "    # plt.scatter(lon,lat,transform=ccrs.Geodetic(),s=1,c=sdcolor)\n",
    "    # plt.title(sdid)\n",
    "    # path = 'maps/sd-track/' + sdid + '.png'\n",
    "    # plt.savefig(path)\n",
    "\n",
    "    # assessing time\n",
    "    date = pd.to_datetime(sd['time'])\n",
    "    sd['time'] = date\n",
    "\n",
    "    # extract the date and hour from the 'datetime' column\n",
    "    sd['date'] = sd['time'].dt.date\n",
    "    sd['hour'] = sd['time'].dt.hour\n",
    "\n",
    "    # group the DataFrame by 'date' and 'hour' and calculate the mean for each group\n",
    "    # this ignores NaN values\n",
    "    lon = sd.groupby(['date', 'hour'])['longitude'].mean().reset_index()\n",
    "    lat = sd.groupby(['date', 'hour'])['latitude'].mean().reset_index()\n",
    "    sd['QL'] = pd.to_numeric(sd['QL'], errors='coerce') \n",
    "    QL = sd.groupby(['date', 'hour'])['QL'].mean().reset_index()\n",
    "    sd['QS'] = pd.to_numeric(sd['QS'], errors='coerce') \n",
    "    QS = sd.groupby(['date', 'hour'])['QS'].mean().reset_index()\n",
    "    sd = pd.DataFrame([lon['date'],lon['hour'],lon['longitude'],lat['latitude'],QL['QL'],QS['QS']])\n",
    "    sdflux = sd.T\n",
    "\n",
    "    # load observation data\n",
    "    if idx2017 == 0:\n",
    "        sd = sd1001\n",
    "    elif idx2017 == 1:\n",
    "        sd = sd1002\n",
    "    elif idx2017 == 2:\n",
    "        sd = sd1003\n",
    "\n",
    "    # assessing time\n",
    "    date0 = sd['datetime']\n",
    "    date = [datetime.utcfromtimestamp(timestamp) for timestamp in date0]\n",
    "    sd['time'] = date\n",
    "\n",
    "    # extract the date and hour from the 'datetime' column\n",
    "    sd['date'] = sd['time'].dt.date\n",
    "    sd['hour'] = sd['time'].dt.hour\n",
    "\n",
    "    # group the DataFrame by 'date' and 'hour' and calculate the mean for each group\n",
    "    # this ignores NaN values\n",
    "    T = sd.groupby(['date', 'hour'])['T'].mean().reset_index() \n",
    "    SST = sd.groupby(['date', 'hour'])['SST'].mean().reset_index()\n",
    "    RH = sd.groupby(['date', 'hour'])['RH'].mean().reset_index()\n",
    "    V = sd.groupby(['date', 'hour'])['V'].mean().reset_index()\n",
    "    p = sd.groupby(['date', 'hour'])['p'].mean().reset_index()\n",
    "    sd = pd.DataFrame([T['date'],T['hour'],T['T'],SST['SST'],RH['RH'],V['V'],p['p']])\n",
    "    sdobs = sd.T\n",
    "    \n",
    "    # merge data\n",
    "    sd = pd.merge(sdflux, sdobs, on=['date', 'hour'], how='inner')\n",
    "    if name == sdname[0]:\n",
    "        sdfull = sd\n",
    "    else:\n",
    "        sdfull = pd.concat([sdfull,sd])\n",
    "\n",
    "# convert 'date' and 'hour' columns to strings\n",
    "sdfull['date'] = sdfull['date'].astype(str)\n",
    "sdfull['hour'] = sdfull['hour'].astype(int).astype(str)\n",
    "\n",
    "# concatenate 'date' and 'hour' columns with a space in between\n",
    "sdfull['datetime'] = sdfull['date'] + ' ' + sdfull['hour'] + ':30:00'\n",
    "\n",
    "# convert the concatenated column to datetime\n",
    "sdfull['datetime'] = pd.to_datetime(sdfull['datetime'])\n",
    "sdfull['datetime'] = sdfull['datetime'].apply(lambda x: x.timestamp())\n",
    "\n",
    "# drop the 'date' and 'hour' columns\n",
    "sdfull.drop(['date', 'hour'], axis=1, inplace=True)\n",
    "sdfull.dropna(inplace=True)\n",
    "\n",
    "# save file\n",
    "sdfull.to_csv('data/sd/avg-at30-2017.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time series #\n",
    "plt.figure()\n",
    "time = pd.to_datetime(sdfull['datetime'],unit='s')\n",
    "QL = sdfull['QL']\n",
    "plt.scatter(time,QL,c='k',s=2)\n",
    "plt.axhline(0,c='k',ls=':')\n",
    "plt.title('Saildrone Q$_L$')\n",
    "plt.ylabel('Flux ($W*m^2$)')\n",
    "path = 'timeseries/SD-QL.png'\n",
    "plt.savefig(path)\n",
    "\n",
    "plt.figure()\n",
    "QS = sdfull['QS']\n",
    "plt.scatter(time,QS,c='k',s=2)\n",
    "plt.axhline(0,c='k',ls=':')\n",
    "plt.title('Saildrone Q$_S$')\n",
    "plt.ylabel('Flux ($W*m^2$)')\n",
    "path = 'timeseries/SD-QS.png'\n",
    "plt.savefig(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arctic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
